############################################################
# ğŸ“˜ æ–‡ä»¶è¯´æ˜ï¼šç¼–æ’MCPå·¥å…·
# æœ¬æ–‡ä»¶å®ç°çš„åŠŸèƒ½ï¼šæ³¨å†Œç¼–æ’ç›¸å…³çš„MCPå·¥å…·
#
# ğŸ“‹ ç¨‹åºæ•´ä½“ä¼ªä»£ç ï¼ˆä¸­æ–‡ï¼‰ï¼š
# 1. åˆå§‹åŒ–ä¾èµ–æ¨¡å—å’Œé…ç½®
# 2. å®šä¹‰æ ¸å¿ƒç±»å’Œå‡½æ•°
# 3. å®ç°ä¸»è¦ä¸šåŠ¡é€»è¾‘
# 4. æä¾›å¯¹å¤–æ¥å£
# 5. å¼‚å¸¸å¤„ç†ä¸æ—¥å¿—è®°å½•
#
# ğŸ”„ ç¨‹åºæµç¨‹å›¾ï¼ˆé€»è¾‘æµï¼‰ï¼š
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  MCP è¯·æ±‚    â”‚
# â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#        â†“
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  å·¥å…·å‡½æ•°å¤„ç† â”‚
# â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#        â†“
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  è¿”å›ç»“æœ    â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# ğŸ“Š æ•°æ®ç®¡é“è¯´æ˜ï¼š
# æ•°æ®æµå‘ï¼šè¾“å…¥æº â†’ æ•°æ®å¤„ç† â†’ æ ¸å¿ƒç®—æ³• â†’ è¾“å‡ºç›®æ ‡
#
# ğŸ§© æ–‡ä»¶ç»“æ„ï¼š
# - å‡½æ•°: register_tools, ai_run_pipeline, ai_enhance_output, ai_provider_snapshot, ai_call_role
#
# ğŸ”— ä¸»è¦ä¾èµ–ï¼šHeablcoin, __future__, cloud, json, orchestration, os, storage, typing
#
# ğŸ•’ åˆ›å»ºæ—¶é—´ï¼š2025-12-18
############################################################

from __future__ import annotations

import json
from typing import Any

from orchestration.router import build_orchestrator_from_env
from orchestration.tasks import build_plan_for_task, parse_context
from orchestration.ai_roles import (
    call_ai, AIRole, AIResponse,
    reason, write, remember, research, critique,
    ROLE_CONFIGS
)
from utils.smart_logger import get_logger
from orchestration.providers import build_default_providers
from cloud.task_manager import enqueue_monitor_task
from storage.notion_adapter import NotionAdapter
from storage.redis_adapter import RedisAdapter

logger = get_logger("system")


def register_tools(mcp: Any) -> None:
    orchestrator = build_orchestrator_from_env()

    @mcp.tool()
    def ai_run_pipeline(task: str = "analysis", user_input: str = "", context: str = "") -> str:
        """å¤šé˜¶æ®µå¤šAIæµæ°´çº¿ï¼šæŒ‰ä»»åŠ¡æ‹†åˆ†åˆ†æ/å¤æ ¸/åˆæˆ"""
        ctx = parse_context(context)
        plan = build_plan_for_task(task=task)
        result = orchestrator.run(plan=plan, user_input=user_input, context=ctx)
        return json.dumps(result, ensure_ascii=False, indent=2)

    @mcp.tool()
    def ai_enhance_output(content: str, tone: str = "concise", context: str = "") -> str:
        """è°ƒç”¨å¤šAIé“¾è·¯å¯¹è¾“å‡ºåšäºŒæ¬¡æ¶¦è‰²ï¼Œä¿æŒäº‹å®ä¸€è‡´"""
        ctx = parse_context(context)
        enhanced = orchestrator.enhance_output(content, context=ctx, tone=tone)
        return enhanced.get("final") or json.dumps(enhanced, ensure_ascii=False, indent=2)

    @mcp.tool()
    def ai_provider_snapshot() -> str:
        """æŸ¥çœ‹å½“å‰å¯ç”¨AIæä¾›å•†ä¸è·¯ç”±"""
        providers = []
        for name, provider in orchestrator.providers.items():
            providers.append({"name": name, "model": getattr(provider, "model", ""), "type": provider.__class__.__name__})
        routes = getattr(orchestrator, "role_routes", {})
        info = {
            "providers": providers,
            "routes": routes,
            "default": orchestrator.default_provider,
        }
        return json.dumps(info, ensure_ascii=False, indent=2)

    # ============================================
    # æ–°å¢ï¼šAI è§’è‰²è°ƒç”¨å·¥å…·
    # ============================================

    @mcp.tool()
    def ai_call_role(
        role: str,
        prompt: str,
        context: str = "",
        max_tokens: int = 1024,
        temperature: float = 0.7,
        forced_endpoint: str = ""
    ) -> str:
        """
        æ ¹æ®è§’è‰²è°ƒç”¨ AIï¼ˆç»Ÿä¸€æ¥å£ï¼‰
        
        Args:
            role: è§’è‰²æ ‡è¯† (ai_reasoning, ai_writer, ai_memory, ai_research, ai_critic)
            prompt: æç¤ºè¯
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ JSON
            max_tokens: æœ€å¤§ç”Ÿæˆé•¿åº¦
            temperature: éšæœºæ€§ (0-1)
            forced_endpoint: æŒ‡å®šç«¯ç‚¹åç§°ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            AI å“åº”ç»“æœ
        """
        ctx = json.loads(context) if context else None
        
        response = call_ai(
            role=role,
            prompt=prompt,
            context=ctx,
            max_tokens=max_tokens,
            temperature=temperature,
            forced_endpoint=forced_endpoint if forced_endpoint else None
        )
        
        return json.dumps({
            "success": response.success,
            "content": response.content,
            "endpoint": response.endpoint,
            "role": response.role,
            "latency": response.latency,
            "parsed": response.parsed,
            "error": response.error
        }, ensure_ascii=False, indent=2)

    @mcp.tool()
    def ai_reason(prompt: str, context: str = "") -> str:
        """
        AI æ¨ç†åˆ†æï¼ˆé£é™©è¯„ä¼°ã€ç­–ç•¥å®¡æ ¸ï¼‰
        
        Args:
            prompt: åˆ†æé—®é¢˜æˆ–å†…å®¹
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ JSON
        """
        ctx = json.loads(context) if context else None
        response = reason(prompt, context=ctx)
        return json.dumps({
            "success": response.success,
            "content": response.content,
            "parsed": response.parsed,
            "error": response.error
        }, ensure_ascii=False, indent=2)

    @mcp.tool()
    def ai_write(prompt: str, tone: str = "professional") -> str:
        """
        AI å†™ä½œï¼ˆæŠ¥å‘Šã€æ—¥è®°ã€é‚®ä»¶ï¼‰
        
        Args:
            prompt: å†™ä½œè¦æ±‚
            tone: è¯­æ°” (professional, casual, formal)
        """
        response = write(prompt, context={"tone": tone})
        return response.content if response.success else f"é”™è¯¯: {response.error}"

    @mcp.tool()
    def ai_remember(prompt: str, documents: str = "") -> str:
        """
        AI è®°å¿†/æ‘˜è¦ï¼ˆé•¿æ–‡æœ¬åˆ†æã€å†å²å›é¡¾ï¼‰
        
        Args:
            prompt: åˆ†æé—®é¢˜
            documents: æ–‡æ¡£å†…å®¹ï¼ˆç”¨æ¢è¡Œåˆ†éš”å¤šä¸ªæ–‡æ¡£ï¼‰
        """
        docs = documents.split("\n---\n") if documents else None
        response = remember(prompt, documents=docs)
        return json.dumps({
            "success": response.success,
            "content": response.content,
            "parsed": response.parsed,
            "error": response.error
        }, ensure_ascii=False, indent=2)

    @mcp.tool()
    def ai_research(query: str, num_sources: int = 5) -> str:
        """
        AI ç ”ç©¶ï¼ˆæ–°é—»æœç´¢ã€å…¬å‘Šåˆ†æï¼‰
        
        Args:
            query: æœç´¢å…³é”®è¯
            num_sources: æ¥æºæ•°é‡
        """
        response = research(query, num_sources=num_sources)
        return json.dumps({
            "success": response.success,
            "content": response.content,
            "parsed": response.parsed,
            "error": response.error
        }, ensure_ascii=False, indent=2)

    @mcp.tool()
    def ai_critique(plan: str, criteria: str = "") -> str:
        """
        AI å®¡æŸ¥/æ‰¹è¯„ï¼ˆç­–ç•¥å®¡æ ¸ã€é£é™©è¯†åˆ«ï¼‰
        
        Args:
            plan: å¾…å®¡æŸ¥çš„è®¡åˆ’æˆ–ç­–ç•¥
            criteria: å®¡æŸ¥æ ‡å‡†ï¼ˆé€—å·åˆ†éš”ï¼‰
        """
        criteria_list = [c.strip() for c in criteria.split(",") if c.strip()] if criteria else None
        response = critique(plan, criteria=criteria_list)
        return json.dumps({
            "success": response.success,
            "content": response.content,
            "parsed": response.parsed,
            "error": response.error
        }, ensure_ascii=False, indent=2)

    @mcp.tool()
    def ai_list_roles() -> str:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ AI è§’è‰²åŠå…¶è¯´æ˜"""
        roles = []
        for role, config in ROLE_CONFIGS.items():
            roles.append({
                "role": role.value,
                "description": config.description,
                "preferred_endpoints": config.preferred_endpoints,
                "output_format": config.output_format,
                "default_temperature": config.default_temperature
            })
        return json.dumps(roles, ensure_ascii=False, indent=2)

    # ==========================================================
    # äº‘ç«¯ååŒå¢å¼º
    # ==========================================================

    @mcp.tool()
    def consult_external_expert(query: str, model: str = "deepseek", context: str = "") -> str:
        """
        è®© Claude å€ŸåŠ©å…¶ä»– AIï¼ˆå¤šäº‘ï¼‰ç»™å‡ºç¬¬äºŒæ„è§ã€‚
        Args:
            query: æç¤º/é—®é¢˜
            model: provider åç§°ï¼ˆopenai/deepseek/anthropic/gemini/groq/moonshot/zhipuï¼‰
            context: å¯é€‰ JSON å­—ç¬¦ä¸²
        """
        providers = build_default_providers()
        provider = providers.get(model)
        if not provider:
            return json.dumps({"success": False, "error": f"model {model} not available"}, ensure_ascii=False, indent=2)
        ctx = json.loads(context) if context else {}
        prompt = query
        if ctx:
            prompt += f"\n\nContext:\n{json.dumps(ctx, ensure_ascii=False, indent=2)}"
        resp = provider.generate(prompt=prompt, system=ctx.get("system_prompt", ""), max_tokens=512, temperature=0.3)
        return json.dumps({
            "success": True,
            "provider": resp.provider or model,
            "model": resp.model,
            "latency": resp.latency,
            "content": resp.text,
        }, ensure_ascii=False, indent=2)

    @mcp.tool()
    def set_cloud_sentry(symbol: str, condition: str, action: str = "notify", notes: str = "") -> str:
        """
        å†™å…¥äº‘ç«¯å“¨å…µä»»åŠ¡ï¼ˆRedis é˜Ÿåˆ—ï¼‰ï¼Œç”±é’é¾™ worker è½®è¯¢æ‰§è¡Œã€‚
        condition æ”¯æŒ price < X / price <= X / price > X / price >= Xã€‚
        """
        task = {
            "symbol": symbol,
            "condition": condition,
            "action": action,
            "notes": notes,
        }
        result = enqueue_monitor_task(task)
        return json.dumps(result, ensure_ascii=False, indent=2)

    @mcp.tool()
    def sync_session_to_notion(summary: str, tags: str = "") -> str:
        """
        å°†å½“å‰ä¼šè¯/åˆ†æç»“è®ºå†™å…¥ Notion æ—¥å¿—åº“ã€‚
        éœ€è¦ NOTION_API_KEY / NOTION_DATABASE_IDï¼ˆæˆ– REPORTS_DB_IDï¼‰ã€‚
        """
        tags_list = [t.strip() for t in tags.split(",") if t.strip()]
        adapter = NotionAdapter()
        res = adapter.append_daily_log(summary, tags=tags_list)
        return json.dumps({
            "success": res.success,
            "location": res.location,
            "message": res.message,
            "error": res.error,
        }, ensure_ascii=False, indent=2)

    @mcp.tool()
    def fetch_portfolio_snapshot() -> str:
        """
        è¿”å›è´¦æˆ·èµ„äº§å¿«ç…§ï¼ˆè°ƒç”¨ Heablcoin.get_account_summaryï¼‰ã€‚
        """
        try:
            from Heablcoin import get_account_summary  # type: ignore
            data = get_account_summary()
            return json.dumps({"success": True, "data": data}, ensure_ascii=False, indent=2)
        except Exception as e:
            return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False, indent=2)

    @mcp.tool()
    def get_learning_context() -> str:
        """
        è¿”å›æœ€è¿‘çš„äº¤æ˜“æ•™è®­/åå¥½ï¼Œæ¥è‡ª dev/lessons.mdï¼ˆå¦‚ä¸å­˜åœ¨åˆ™è¿”å›å ä½æç¤ºï¼‰ã€‚
        """
        import os
        path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "dev", "lessons.md")
        if not os.path.exists(path):
            return "æš‚æ—  lessonsï¼Œå¯åœ¨ dev/lessons.md ä¸­æ·»åŠ ä½ çš„æ•™è®­/åå¥½ã€‚"
        try:
            with open(path, "r", encoding="utf-8") as f:
                content = f.read()
            return content.strip() or "æ–‡ä»¶ä¸ºç©ºï¼Œè¯·å¡«å…¥æ•™è®­/åå¥½ã€‚"
        except Exception as e:
            return f"è¯»å–å¤±è´¥: {e}"
