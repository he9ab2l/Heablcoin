############################################################
# ğŸ“˜ æ–‡ä»¶è¯´æ˜ï¼š
# æœ¬æ–‡ä»¶å®ç°çš„åŠŸèƒ½ï¼šåŸºæœ¬é¢åˆ†ææ¨¡å—
#
# ğŸ“‹ ç¨‹åºæ•´ä½“ä¼ªä»£ç ï¼ˆä¸­æ–‡ï¼‰ï¼š
# 1. åˆå§‹åŒ–ä¸»è¦ä¾èµ–ä¸å˜é‡
# 2. åŠ è½½è¾“å…¥æ•°æ®æˆ–æ¥æ”¶å¤–éƒ¨è¯·æ±‚
# 3. æ‰§è¡Œä¸»è¦é€»è¾‘æ­¥éª¤ï¼ˆå¦‚è®¡ç®—ã€å¤„ç†ã€è®­ç»ƒã€æ¸²æŸ“ç­‰ï¼‰
# 4. è¾“å‡ºæˆ–è¿”å›ç»“æœ
# 5. å¼‚å¸¸å¤„ç†ä¸èµ„æºé‡Šæ”¾
#
# ğŸ”„ ç¨‹åºæµç¨‹å›¾ï¼ˆé€»è¾‘æµï¼‰ï¼š
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  è¾“å…¥æ•°æ® â”‚
# â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
#       â†“
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  æ ¸å¿ƒå¤„ç†é€»è¾‘ â”‚
# â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
#       â†“
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  è¾“å‡ºç»“æœ â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# ğŸ“Š æ•°æ®ç®¡é“è¯´æ˜ï¼š
# æ•°æ®æµå‘ï¼šè¾“å…¥æº â†’ æ•°æ®æ¸…æ´—/è½¬æ¢ â†’ æ ¸å¿ƒç®—æ³•æ¨¡å— â†’ è¾“å‡ºç›®æ ‡ï¼ˆæ–‡ä»¶ / æ¥å£ / ç»ˆç«¯ï¼‰
#
# ğŸ§© æ–‡ä»¶ç»“æ„ï¼š
# - ä¾èµ–ï¼ˆæ ‡å‡†åº“ï¼‰ï¼š__future__, datetime, json, typing
# - ä¾èµ–ï¼ˆç¬¬ä¸‰æ–¹ï¼‰ï¼šæ— 
# - ä¾èµ–ï¼ˆæœ¬åœ°ï¼‰ï¼šcore.orchestration.ai_roles, utils.smart_logger
#
# ğŸ•’ åˆ›å»ºæ—¶é—´ï¼š2025-12-19
############################################################

"""
åŸºæœ¬é¢åˆ†ææ¨¡å—
==============
è´Ÿè´£åˆ†æå¸‚åœºåŸºæœ¬é¢ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–°é—»ã€å…¬å‘Šã€é“¾ä¸Šæ•°æ®ç­‰ã€‚
ä½¿ç”¨ ai_research è§’è‰²è·å–å’Œåˆ†æä¿¡æ¯ã€‚
"""

from __future__ import annotations

import json
from datetime import datetime
from typing import Any, Dict, List, Optional

from core.orchestration.ai_roles import research, call_ai, AIRole
from utils.smart_logger import get_logger

logger = get_logger("fundamental")


class FundamentalAnalyzer:
    """åŸºæœ¬é¢åˆ†æå™¨"""
    
    def __init__(self):
        self.logger = logger
    
    def analyze_news(self, symbol: str, num_sources: int = 5) -> Dict[str, Any]:
        """
        åˆ†ææ–°é—»å’Œå¸‚åœºæƒ…ç»ª
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            num_sources: æ–°é—»æ¥æºæ•°é‡
        
        Returns:
            Dict: æ–°é—»åˆ†æç»“æœ
        """
        try:
            # æ„å»ºæœç´¢æŸ¥è¯¢
            query = f"{symbol} cryptocurrency news latest market sentiment"
            
            # ä½¿ç”¨ AI ç ”ç©¶è§’è‰²è·å–æ–°é—»
            response = research(query, num_sources=num_sources)
            
            if not response.success:
                return {
                    "success": False,
                    "error": response.error,
                    "symbol": symbol
                }
            
            # è§£ææ–°é—»æ•°æ®
            news_data = response.parsed or {}
            
            # ä½¿ç”¨ AI æ¨ç†è§’è‰²åˆ†ææƒ…ç»ª
            sentiment_prompt = f"""
åˆ†æä»¥ä¸‹å…³äº {symbol} çš„æ–°é—»å†…å®¹ï¼Œè¯„ä¼°å¸‚åœºæƒ…ç»ªï¼š

{response.content}

è¯·æä¾›ï¼š
1. æ•´ä½“æƒ…ç»ªè¯„åˆ†ï¼ˆ0-100ï¼Œ0=æåº¦æ‚²è§‚ï¼Œ100=æåº¦ä¹è§‚ï¼‰
2. ä¸»è¦åˆ©å¥½å› ç´ 
3. ä¸»è¦åˆ©ç©ºå› ç´ 
4. çŸ­æœŸå½±å“é¢„æµ‹
5. å»ºè®®æ“ä½œ

ä»¥ JSON æ ¼å¼è¾“å‡ºã€‚
"""
            
            sentiment_response = call_ai(
                role=AIRole.REASONING,
                prompt=sentiment_prompt,
                max_tokens=1024,
                temperature=0.3
            )
            
            sentiment_analysis = sentiment_response.parsed or {}
            
            return {
                "success": True,
                "symbol": symbol,
                "timestamp": datetime.now().isoformat(),
                "news_sources": num_sources,
                "raw_news": response.content,
                "sentiment_score": sentiment_analysis.get("sentiment_score", 50),
                "bullish_factors": sentiment_analysis.get("bullish_factors", []),
                "bearish_factors": sentiment_analysis.get("bearish_factors", []),
                "short_term_impact": sentiment_analysis.get("short_term_impact", "neutral"),
                "recommendation": sentiment_analysis.get("recommendation", "hold"),
                "analysis_endpoint": response.endpoint
            }
            
        except Exception as e:
            logger.error(f"News analysis failed for {symbol}: {e}")
            return {
                "success": False,
                "error": str(e),
                "symbol": symbol
            }
    
    def analyze_on_chain(self, symbol: str) -> Dict[str, Any]:
        """
        åˆ†æé“¾ä¸Šæ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
        
        Returns:
            Dict: é“¾ä¸Šæ•°æ®åˆ†æç»“æœ
        """
        try:
            # æ„å»ºæŸ¥è¯¢
            query = f"{symbol} on-chain metrics whale activity network activity"
            
            # è·å–é“¾ä¸Šæ•°æ®ä¿¡æ¯
            response = research(query, num_sources=3)
            
            if not response.success:
                return {
                    "success": False,
                    "error": response.error,
                    "symbol": symbol
                }
            
            # åˆ†æé“¾ä¸ŠæŒ‡æ ‡
            analysis_prompt = f"""
åˆ†æä»¥ä¸‹å…³äº {symbol} çš„é“¾ä¸Šæ•°æ®ï¼š

{response.content}

è¯·è¯„ä¼°ï¼š
1. å·¨é²¸æ´»åŠ¨æƒ…å†µ
2. ç½‘ç»œæ´»è·ƒåº¦
3. äº¤æ˜“æ‰€æµå…¥æµå‡º
4. æŒå¸åœ°å€å˜åŒ–
5. é“¾ä¸Šä¿¡å·ï¼ˆçœ‹æ¶¨/çœ‹è·Œï¼‰

ä»¥ JSON æ ¼å¼è¾“å‡ºã€‚
"""
            
            analysis_response = call_ai(
                role=AIRole.REASONING,
                prompt=analysis_prompt,
                max_tokens=1024,
                temperature=0.3
            )
            
            on_chain_data = analysis_response.parsed or {}
            
            return {
                "success": True,
                "symbol": symbol,
                "timestamp": datetime.now().isoformat(),
                "whale_activity": on_chain_data.get("whale_activity", "unknown"),
                "network_activity": on_chain_data.get("network_activity", "unknown"),
                "exchange_flow": on_chain_data.get("exchange_flow", "unknown"),
                "address_change": on_chain_data.get("address_change", "unknown"),
                "on_chain_signal": on_chain_data.get("on_chain_signal", "neutral"),
                "raw_data": response.content
            }
            
        except Exception as e:
            logger.error(f"On-chain analysis failed for {symbol}: {e}")
            return {
                "success": False,
                "error": str(e),
                "symbol": symbol
            }
    
    def get_market_events(self, symbol: str) -> Dict[str, Any]:
        """
        è·å–å¸‚åœºé‡å¤§äº‹ä»¶
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
        
        Returns:
            Dict: å¸‚åœºäº‹ä»¶ä¿¡æ¯
        """
        try:
            query = f"{symbol} major events announcements partnerships regulations"
            
            response = research(query, num_sources=5)
            
            if not response.success:
                return {
                    "success": False,
                    "error": response.error,
                    "symbol": symbol
                }
            
            # æå–å’Œåˆ†ç±»äº‹ä»¶
            events_prompt = f"""
ä»ä»¥ä¸‹ä¿¡æ¯ä¸­æå–å…³äº {symbol} çš„é‡å¤§äº‹ä»¶ï¼š

{response.content}

è¯·åˆ†ç±»ä¸ºï¼š
1. æŠ€æœ¯æ›´æ–°/å‡çº§
2. åˆä½œä¼™ä¼´å…³ç³»
3. ç›‘ç®¡æ¶ˆæ¯
4. å¸‚åœºåŠ¨æ€
5. å…¶ä»–é‡è¦äº‹ä»¶

æ¯ä¸ªäº‹ä»¶åŒ…å«ï¼šæ—¶é—´ã€ç±»å‹ã€æè¿°ã€å½±å“è¯„ä¼°ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰

ä»¥ JSON æ ¼å¼è¾“å‡ºã€‚
"""
            
            events_response = call_ai(
                role=AIRole.REASONING,
                prompt=events_prompt,
                max_tokens=1536,
                temperature=0.3
            )
            
            events_data = events_response.parsed or {}
            
            return {
                "success": True,
                "symbol": symbol,
                "timestamp": datetime.now().isoformat(),
                "events": events_data.get("events", []),
                "overall_impact": events_data.get("overall_impact", "neutral"),
                "raw_info": response.content
            }
            
        except Exception as e:
            logger.error(f"Market events analysis failed for {symbol}: {e}")
            return {
                "success": False,
                "error": str(e),
                "symbol": symbol
            }
    
    def comprehensive_fundamental_analysis(self, symbol: str) -> Dict[str, Any]:
        """
        ç»¼åˆåŸºæœ¬é¢åˆ†æ
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
        
        Returns:
            Dict: ç»¼åˆåˆ†æç»“æœ
        """
        try:
            # å¹¶è¡Œè·å–å„ç±»ä¿¡æ¯
            news_analysis = self.analyze_news(symbol)
            on_chain_analysis = self.analyze_on_chain(symbol)
            market_events = self.get_market_events(symbol)
            
            # ç»¼åˆè¯„ä¼°
            ç»¼åˆ_prompt = f"""
åŸºäºä»¥ä¸‹ä¸‰ä¸ªç»´åº¦çš„åˆ†æï¼Œç»™å‡º {symbol} çš„ç»¼åˆåŸºæœ¬é¢è¯„ä¼°ï¼š

1. æ–°é—»æƒ…ç»ªåˆ†æï¼š
{json.dumps(news_analysis, ensure_ascii=False, indent=2)}

2. é“¾ä¸Šæ•°æ®åˆ†æï¼š
{json.dumps(on_chain_analysis, ensure_ascii=False, indent=2)}

3. å¸‚åœºäº‹ä»¶åˆ†æï¼š
{json.dumps(market_events, ensure_ascii=False, indent=2)}

è¯·æä¾›ï¼š
1. ç»¼åˆè¯„åˆ†ï¼ˆ0-100ï¼‰
2. åŸºæœ¬é¢å¼ºåº¦ï¼ˆå¼º/ä¸­/å¼±ï¼‰
3. ä¸»è¦é©±åŠ¨å› ç´ 
4. é£é™©å› ç´ 
5. æŠ•èµ„å»ºè®®ï¼ˆå¼ºçƒˆä¹°å…¥/ä¹°å…¥/æŒæœ‰/å–å‡º/å¼ºçƒˆå–å‡ºï¼‰
6. æ—¶é—´æ¡†æ¶å»ºè®®ï¼ˆçŸ­æœŸ/ä¸­æœŸ/é•¿æœŸï¼‰

ä»¥ JSON æ ¼å¼è¾“å‡ºã€‚
"""
            
            comprehensive_response = call_ai(
                role=AIRole.REASONING,
                prompt=ç»¼åˆ_prompt,
                max_tokens=1536,
                temperature=0.3
            )
            
            comprehensive_data = comprehensive_response.parsed or {}
            
            return {
                "success": True,
                "symbol": symbol,
                "timestamp": datetime.now().isoformat(),
                "comprehensive_score": comprehensive_data.get("comprehensive_score", 50),
                "fundamental_strength": comprehensive_data.get("fundamental_strength", "medium"),
                "key_drivers": comprehensive_data.get("key_drivers", []),
                "risk_factors": comprehensive_data.get("risk_factors", []),
                "recommendation": comprehensive_data.get("recommendation", "hold"),
                "timeframe": comprehensive_data.get("timeframe", "medium-term"),
                "components": {
                    "news": news_analysis,
                    "on_chain": on_chain_analysis,
                    "events": market_events
                }
            }
            
        except Exception as e:
            logger.error(f"Comprehensive fundamental analysis failed for {symbol}: {e}")
            return {
                "success": False,
                "error": str(e),
                "symbol": symbol
            }


# å…¨å±€å®ä¾‹
_fundamental_analyzer: Optional[FundamentalAnalyzer] = None


def get_fundamental_analyzer() -> FundamentalAnalyzer:
    """è·å–å…¨å±€åŸºæœ¬é¢åˆ†æå™¨å®ä¾‹"""
    global _fundamental_analyzer
    if _fundamental_analyzer is None:
        _fundamental_analyzer = FundamentalAnalyzer()
    return _fundamental_analyzer
