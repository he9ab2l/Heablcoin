############################################################
# ğŸ“˜ æ–‡ä»¶è¯´æ˜ï¼š
# æœ¬æ–‡ä»¶å®ç°çš„åŠŸèƒ½ï¼šQuantitative research helper utilities.
#
# ğŸ“‹ ç¨‹åºæ•´ä½“ä¼ªä»£ç ï¼ˆä¸­æ–‡ï¼‰ï¼š
# 1. åˆå§‹åŒ–ä¸»è¦ä¾èµ–ä¸å˜é‡
# 2. åŠ è½½è¾“å…¥æ•°æ®æˆ–æ¥æ”¶å¤–éƒ¨è¯·æ±‚
# 3. æ‰§è¡Œä¸»è¦é€»è¾‘æ­¥éª¤ï¼ˆå¦‚è®¡ç®—ã€å¤„ç†ã€è®­ç»ƒã€æ¸²æŸ“ç­‰ï¼‰
# 4. è¾“å‡ºæˆ–è¿”å›ç»“æœ
# 5. å¼‚å¸¸å¤„ç†ä¸èµ„æºé‡Šæ”¾
#
# ğŸ”„ ç¨‹åºæµç¨‹å›¾ï¼ˆé€»è¾‘æµï¼‰ï¼š
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  è¾“å…¥æ•°æ® â”‚
# â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
#       â†“
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  æ ¸å¿ƒå¤„ç†é€»è¾‘ â”‚
# â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
#       â†“
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  è¾“å‡ºç»“æœ â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# ğŸ“Š æ•°æ®ç®¡é“è¯´æ˜ï¼š
# æ•°æ®æµå‘ï¼šè¾“å…¥æº â†’ æ•°æ®æ¸…æ´—/è½¬æ¢ â†’ æ ¸å¿ƒç®—æ³•æ¨¡å— â†’ è¾“å‡ºç›®æ ‡ï¼ˆæ–‡ä»¶ / æ¥å£ / ç»ˆç«¯ï¼‰
#
# ğŸ§© æ–‡ä»¶ç»“æ„ï¼š
# - ä¾èµ–ï¼ˆæ ‡å‡†åº“ï¼‰ï¼š__future__, dataclasses, datetime, json, typing
# - ä¾èµ–ï¼ˆç¬¬ä¸‰æ–¹ï¼‰ï¼šæ— 
# - ä¾èµ–ï¼ˆæœ¬åœ°ï¼‰ï¼šcore.orchestration.ai_roles, storage.notion_adapter, utils.smart_logger
#
# ğŸ•’ åˆ›å»ºæ—¶é—´ï¼š2025-12-19
############################################################

"""Quantitative research helper utilities."""

from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, Iterable, List, Optional

from core.orchestration.ai_roles import (
    AIRole,
    AIResponse,
    call_ai,
    research as ai_research_call,
)
from storage.notion_adapter import NotionAdapter
from utils.smart_logger import get_logger

logger = get_logger("quant_research")


FOCUS_HINTS: Dict[str, str] = {
    "balanced": "åŒæ—¶è¯„ä¼° alpha æœºä¼šã€é£é™©äº‹ä»¶ã€èµ„é‡‘æµä¸æ‰§è¡Œæ¡ä»¶ï¼Œè¾“å‡ºå…¨é¢è§†è§’",
    "alpha": "èšç„¦å¯æ“ä½œçš„ alpha æ¥æºï¼ˆé”™ä»·ã€ç»“æ„æ€§æœºä¼šã€äº‹ä»¶é©±åŠ¨ã€ç»Ÿè®¡å¥—åˆ©ï¼‰",
    "risk": "å¼ºè°ƒå°¾éƒ¨é£é™©ã€æ æ†è„†å¼±æ€§ã€èµ„é‡‘é“¾æ–­è£‚ã€æ”¿ç­–ä¸ç¡®å®šæ€§",
    "macro": "çº³å…¥å®è§‚ä¸è·¨å¸‚åœºä¿¡æ¯ï¼Œè§‚å¯Ÿç¾å…ƒæµåŠ¨æ€§ã€æ”¶ç›Šç‡æ›²çº¿ã€å¤®è¡ŒæŒ‡å¼•",
}


@dataclass(frozen=True)
class ResearchSection:
    """Prompt template metadata."""

    identifier: str
    title: str
    prompt_template: str


SECTION_PRESETS: List[ResearchSection] = [
    ResearchSection(
        identifier="market_regime",
        title="å¸‚åœºç»“æ„ä¸æ³¢åŠ¨ç‡",
        prompt_template=(
            "å›´ç»• {topic} ï¼Œæ€»ç»“å½“å‰å¸‚åœºç»“æ„ã€æ³¢åŠ¨ç‡çŠ¶æ€ä»¥åŠå¾®è§‚ç»“æ„ä¿¡å·ã€‚"
            "è¯·é‡åŒ–æè¿°ï¼ˆå¦‚ realized/ implied volã€è®¢å•ç°¿æ·±åº¦ã€æŒä»“é›†ä¸­åº¦ï¼‰ï¼Œå¹¶ç€é‡ {lens} ã€‚"
            "è¾“å‡ºè¦ç‚¹ + æ•°æ®æ¥æºã€‚"
        ),
    ),
    ResearchSection(
        identifier="flow_and_depth",
        title="èµ„é‡‘æµå‘ä¸æ·±åº¦",
        prompt_template=(
            "è°ƒç ” {topic} ç›¸å…³çš„èµ„é‡‘æµå‘ï¼ˆé“¾ä¸Šã€äº¤æ˜“æ‰€ã€åŸºé‡‘ï¼‰ä¸æµåŠ¨æ€§æ·±åº¦ã€‚"
            "æ ‡æ³¨é²¸é±¼/æœºæ„/ETF ç­‰å…³é”®ä¸»ä½“åŠ¨å‘ï¼Œç»“åˆ {lens} è¯´æ˜æ½œåœ¨å½±å“ã€‚"
        ),
    ),
    ResearchSection(
        identifier="derivatives",
        title="è¡ç”Ÿå“ä¸æ æ†",
        prompt_template=(
            "é’ˆå¯¹ {topic} ï¼Œæ¢³ç†æ°¸ç»­ã€æœŸæƒç­‰è¡ç”Ÿå“æŒ‡æ ‡ï¼ˆèµ„é‡‘è´¹ç‡ã€IV æ›²é¢ã€OI åˆ†å¸ƒï¼‰ã€‚"
            "è¯´æ˜æ æ†ç»“æ„å¯¹ {lens} çš„æç¤ºã€‚"
        ),
    ),
    ResearchSection(
        identifier="alpha_streams",
        title="å¯æ‰§è¡Œ Alpha çº¿ç´¢",
        prompt_template=(
            "åˆ—ä¸¾ä¸ {topic} ç›¸å…³çš„ 2-3 æ¡æ½œåœ¨ alpha æˆ–äº¤æ˜“æ€è·¯ï¼ˆè·¨æœŸã€è·¨å“ã€ç»Ÿè®¡å…³ç³»ã€é“¾ä¸Šæ•°æ®ï¼‰ã€‚"
            "è¦æ±‚ç»“åˆ {lens} ï¼Œç»™å‡ºå‡è®¾ã€è§¦å‘æ¡ä»¶ã€æ•°æ®æ¥æºã€‚"
        ),
    ),
    ResearchSection(
        identifier="risk_radar",
        title="é£é™©äº‹ä»¶ä¸é˜²å¾¡",
        prompt_template=(
            "ç›˜ç‚¹ä¸ {topic} æœ‰å…³çš„ä¸»è¦é£é™©äº‹ä»¶ï¼ˆæ”¿ç­–ã€æŠ€æœ¯ã€æ¸…ç®—ã€èµ„æ–¹è¡Œä¸ºï¼‰ï¼Œ"
            "å¹¶ç»“åˆ {lens} ç»™å‡ºç›‘æ§æŒ‡æ ‡ä¸é˜²å¾¡å»ºè®®ã€‚"
        ),
    ),
]


def _normalize_focus(focus: str) -> str:
    key = (focus or "balanced").strip().lower()
    if key not in FOCUS_HINTS:
        key = "balanced"
    return key


def generate_quant_prompts(
    topic: str,
    focus: str = "balanced",
    sections: Optional[Iterable[str]] = None,
) -> List[Dict[str, str]]:
    """Return prompt set for quant research."""
    focus_key = _normalize_focus(focus)
    selected_ids = {s.strip() for s in sections or [] if s.strip()}
    prompts: List[Dict[str, str]] = []
    for section in SECTION_PRESETS:
        if selected_ids and section.identifier not in selected_ids:
            continue
        prompt_text = section.prompt_template.format(topic=topic, lens=FOCUS_HINTS[focus_key])
        prompts.append(
            {
                "id": section.identifier,
                "title": section.title,
                "prompt": prompt_text,
            }
        )
    return prompts


def _summarize_sections(topic: str, focus: str, sections: List[Dict[str, Any]]) -> Dict[str, Any]:
    raw_bundle = json.dumps(sections, ensure_ascii=False, indent=2)
    summary_prompt = f"""
ä½ æ˜¯èµ„æ·±é‡åŒ–ç ”ç©¶ä¸»ç®¡ã€‚ä¸»é¢˜: {topic} ã€‚è§†è§’: {focus} ã€‚
è¯·é˜…è¯»ä»¥ä¸‹ JSON ä¸­çš„ç ”ç©¶æ‘˜è¦ï¼Œè¾“å‡º JSONï¼ŒåŒ…å«:
- \"market_snapshot\": æ ¸å¿ƒæ€åŠ¿æè¿°ï¼ˆå­—ç¬¦ä¸²ï¼‰
- \"alpha_ideas\": 1-3 æ¡å¯æ‰§è¡Œæƒ³æ³•ï¼ˆæ•°ç»„ï¼‰
- \"risk_notes\": ä¸»è¦é£é™©æç¤ºï¼ˆæ•°ç»„ï¼‰
- \"data_sources\": é‡è¦æ¥æºï¼ˆæ•°ç»„ï¼‰

<research>
{raw_bundle}
</research>
"""
    response = call_ai(
        role=AIRole.REASONING,
        prompt=summary_prompt,
        max_tokens=1200,
        temperature=0.25,
    )
    parsed: Optional[Dict[str, Any]] = None
    if response.success:
        try:
            parsed = json.loads(response.content)
        except json.JSONDecodeError:
            parsed = None
    return {
        "raw": response.content,
        "parsed": parsed,
        "success": response.success,
        "error": response.error,
        "endpoint": response.endpoint,
    }


def _build_markdown(
    topic: str,
    focus: str,
    prompts: List[Dict[str, str]],
    sections: List[Dict[str, Any]],
    summary: Dict[str, Any],
) -> str:
    lines = [
        f"# {topic} é‡åŒ–ç ”ç©¶å¿«æŠ¥",
        "",
        f"- ç ”ç©¶è§†è§’: **{focus}**",
        f"- æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "## ç»“æ„åŒ–æ‘˜è¦",
    ]
    parsed = summary.get("parsed") or {}
    if parsed:
        lines.append("```json")
        lines.append(json.dumps(parsed, ensure_ascii=False, indent=2))
        lines.append("```")
    else:
        lines.append(summary.get("raw") or "æš‚æ— æ‘˜è¦")
    lines.append("")
    for section, prompt in zip(sections, prompts):
        lines.append(f"## {prompt['title']}")
        lines.append(f"**Prompt**: {prompt['prompt']}")
        if section.get("success"):
            lines.append("**Result**:")
            lines.append(section.get("content") or "")
        else:
            lines.append(f"**Error**: {section.get('error')}")
        lines.append("")
    return "\n".join(lines).strip()


def execute_quant_research(
    topic: str,
    *,
    focus: str = "balanced",
    sections: Optional[Iterable[str]] = None,
    num_sources: int = 4,
    save_to_notion: bool = False,
    tags: Optional[Iterable[str]] = None,
) -> Dict[str, Any]:
    """Run ai_research across curated prompts and aggregate results."""
    prompts = generate_quant_prompts(topic=topic, focus=focus, sections=sections)
    outputs: List[Dict[str, Any]] = []
    for prompt in prompts:
        resp: AIResponse = ai_research_call(prompt["prompt"], num_sources=num_sources)
        entry = {
            "section": prompt["id"],
            "title": prompt["title"],
            "prompt": prompt["prompt"],
            "success": resp.success,
            "content": resp.content,
            "error": resp.error,
            "endpoint": resp.endpoint,
        }
        outputs.append(entry)
    summary = _summarize_sections(topic, focus, outputs)
    markdown = _build_markdown(topic, focus, prompts, outputs, summary)
    notion_payload: Optional[Dict[str, Any]] = None
    if save_to_notion:
        adapter = NotionAdapter()
        storage = adapter.save_report(
            title=f"{topic} Quant Research",
            content=markdown,
            report_type="QuantResearch",
            symbol=topic,
            tags=[t.strip() for t in (tags or []) if t.strip()],
        )
        notion_payload = {
            "success": storage.success,
            "location": storage.location,
            "message": storage.message,
            "error": storage.error,
        }
    return {
        "topic": topic,
        "focus": focus,
        "prompts": prompts,
        "sections": outputs,
        "summary": summary,
        "notion": notion_payload,
        "generated_at": datetime.now().isoformat(),
    }


__all__ = ["generate_quant_prompts", "execute_quant_research"]
