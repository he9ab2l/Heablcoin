############################################################
# ğŸ“˜ æ–‡ä»¶è¯´æ˜ï¼šä»»åŠ¡æ‰§è¡Œå™¨
# æœ¬æ–‡ä»¶å®ç°çš„åŠŸèƒ½ï¼šä»ä»»åŠ¡é˜Ÿåˆ—å–ä»»åŠ¡æ‰§è¡Œå¹¶å›å¡«ç»“æœ
#
# ğŸ“‹ ç¨‹åºæ•´ä½“ä¼ªä»£ç ï¼ˆä¸­æ–‡ï¼‰ï¼š
# 1. åˆå§‹åŒ–ä¾èµ–æ¨¡å—å’Œé…ç½®
# 2. å®šä¹‰æ ¸å¿ƒç±»å’Œå‡½æ•°
# 3. å®ç°ä¸»è¦ä¸šåŠ¡é€»è¾‘
# 4. æä¾›å¯¹å¤–æ¥å£
# 5. å¼‚å¸¸å¤„ç†ä¸æ—¥å¿—è®°å½•
#
# ğŸ”„ ç¨‹åºæµç¨‹å›¾ï¼ˆé€»è¾‘æµï¼‰ï¼š
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  è¾“å…¥æ•°æ®    â”‚
# â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#        â†“
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  æ ¸å¿ƒå¤„ç†é€»è¾‘ â”‚
# â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#        â†“
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  è¾“å‡ºç»“æœ    â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# ğŸ“Š æ•°æ®ç®¡é“è¯´æ˜ï¼š
# æ•°æ®æµå‘ï¼šMCPè¯·æ±‚ â†’ ä»»åŠ¡é˜Ÿåˆ— â†’ äº‘ç«¯æ‰§è¡Œ â†’ ç»“æœå›è°ƒ
#
# ğŸ§© æ–‡ä»¶ç»“æ„ï¼š
# - ç±»: TaskType, TaskPayload, ExecutionResult
# - å‡½æ•°: get_task_executor, start_executor, stop_executor, submit_task, to_dict
#
# ğŸ”— ä¸»è¦ä¾èµ–ï¼š__future__, cloud, dataclasses, datetime, enum, json, market_analysis, orchestration
#
# ğŸ•’ åˆ›å»ºæ—¶é—´ï¼š2025-12-18
############################################################

"""
äº‘ç«¯ä»»åŠ¡æ‰§è¡Œå™¨
==============
å®ˆæŠ¤è¿›ç¨‹ï¼Œä»ä»»åŠ¡é˜Ÿåˆ—ä¸­å–ä»»åŠ¡æ‰§è¡Œï¼Œå¹¶å°†ç»“æœå›å¡«ã€‚
æ ¹æ®è®¡åˆ’ä¹¦çš„æŒ‡æŒ¥é“¾è®¾è®¡ï¼Œå®ç° MCPâ†’äº‘ç«¯â†’AI çš„å®Œæ•´é“¾è·¯ã€‚
"""

from __future__ import annotations

import json
import time
import threading
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Callable, Dict, List, Optional, Union
from enum import Enum

from .enhanced_publisher import (
    EnhancedCloudTaskPublisher,
    EnhancedCloudTask,
    TaskStatus,
    TaskPriority,
)
from utils.smart_logger import get_logger

logger = get_logger("task_executor")


class TaskType(str, Enum):
    """æ ‡å‡†ä»»åŠ¡ç±»å‹"""
    MARKET_ANALYSIS = "market_analysis"
    PERSONAL_ANALYSIS = "personal_analysis"
    REPORT_GENERATION = "report_generation"
    AI_CALL = "ai_call"
    NOTIFICATION = "notification"
    DATA_FETCH = "data_fetch"
    STORAGE_SAVE = "storage_save"
    CUSTOM = "custom"


@dataclass
class TaskPayload:
    """æ ‡å‡†ä»»åŠ¡ Payload æ ¼å¼"""
    task_type: TaskType
    action: str  # å…·ä½“åŠ¨ä½œ
    params: Dict[str, Any] = field(default_factory=dict)
    context: Optional[Dict[str, Any]] = None
    output_format: str = "json"  # json, markdown, html
    storage_target: Optional[str] = None  # file, notion, email
    notify_on_complete: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_type": self.task_type.value if isinstance(self.task_type, TaskType) else self.task_type,
            "action": self.action,
            "params": self.params,
            "context": self.context,
            "output_format": self.output_format,
            "storage_target": self.storage_target,
            "notify_on_complete": self.notify_on_complete,
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "TaskPayload":
        task_type = data.get("task_type", "custom")
        if isinstance(task_type, str):
            try:
                task_type = TaskType(task_type)
            except ValueError:
                task_type = TaskType.CUSTOM
        
        return cls(
            task_type=task_type,
            action=data.get("action", ""),
            params=data.get("params", {}),
            context=data.get("context"),
            output_format=data.get("output_format", "json"),
            storage_target=data.get("storage_target"),
            notify_on_complete=data.get("notify_on_complete", False),
        )


@dataclass
class ExecutionResult:
    """ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    success: bool
    output: Any = None
    error: Optional[str] = None
    execution_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)


class TaskHandler:
    """ä»»åŠ¡å¤„ç†å™¨åŸºç±»"""
    
    def can_handle(self, payload: TaskPayload) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤„ç†æ­¤ä»»åŠ¡"""
        return False
    
    def execute(self, payload: TaskPayload) -> ExecutionResult:
        """æ‰§è¡Œä»»åŠ¡"""
        raise NotImplementedError


class MarketAnalysisHandler(TaskHandler):
    """å¸‚åœºåˆ†æä»»åŠ¡å¤„ç†å™¨"""
    
    def can_handle(self, payload: TaskPayload) -> bool:
        return payload.task_type == TaskType.MARKET_ANALYSIS
    
    def execute(self, payload: TaskPayload) -> ExecutionResult:
        start_time = time.time()
        try:
            symbol = payload.params.get("symbol", "BTC/USDT")
            analysis_type = payload.action or "technical"
            
            # å¯¼å…¥å¸‚åœºåˆ†ææ¨¡å—
            from skills.market_analysis.core import MarketAnalyzer
            
            analyzer = MarketAnalyzer()
            
            if analysis_type == "technical":
                result = analyzer.analyze_technical(symbol)
            elif analysis_type == "sentiment":
                result = analyzer.analyze_sentiment(symbol)
            elif analysis_type == "full":
                result = analyzer.analyze_full(symbol)
            else:
                result = analyzer.analyze_technical(symbol)
            
            return ExecutionResult(
                success=True,
                output=result,
                execution_time=time.time() - start_time
            )
            
        except Exception as e:
            logger.error(f"Market analysis failed: {e}")
            return ExecutionResult(
                success=False,
                error=str(e),
                execution_time=time.time() - start_time
            )


class AICallHandler(TaskHandler):
    """AI è°ƒç”¨ä»»åŠ¡å¤„ç†å™¨"""
    
    def can_handle(self, payload: TaskPayload) -> bool:
        return payload.task_type == TaskType.AI_CALL
    
    def execute(self, payload: TaskPayload) -> ExecutionResult:
        start_time = time.time()
        try:
            from core.orchestration.ai_roles import call_ai, AIRole
            
            role = payload.params.get("role", "ai_reasoning")
            prompt = payload.params.get("prompt", "")
            context = payload.context
            
            if not prompt:
                return ExecutionResult(
                    success=False,
                    error="Missing prompt parameter",
                    execution_time=time.time() - start_time
                )
            
            response = call_ai(
                role=role,
                prompt=prompt,
                context=context,
                max_tokens=payload.params.get("max_tokens"),
                temperature=payload.params.get("temperature"),
                forced_endpoint=payload.params.get("forced_endpoint"),
            )
            
            return ExecutionResult(
                success=response.success,
                output={
                    "content": response.content,
                    "parsed": response.parsed,
                    "endpoint": response.endpoint,
                    "role": response.role,
                },
                error=response.error,
                execution_time=time.time() - start_time,
                metadata={"latency": response.latency}
            )
            
        except Exception as e:
            logger.error(f"AI call failed: {e}")
            return ExecutionResult(
                success=False,
                error=str(e),
                execution_time=time.time() - start_time
            )


class ReportGenerationHandler(TaskHandler):
    """æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å¤„ç†å™¨"""
    
    def can_handle(self, payload: TaskPayload) -> bool:
        return payload.task_type == TaskType.REPORT_GENERATION
    
    def execute(self, payload: TaskPayload) -> ExecutionResult:
        start_time = time.time()
        try:
            report_type = payload.action or "daily"
            
            # æ ¹æ®æŠ¥å‘Šç±»å‹ç”Ÿæˆ
            if report_type == "daily":
                from skills.report.flexible_report.service import generate_daily_report
                result = generate_daily_report()
            elif report_type == "analysis":
                symbol = payload.params.get("symbol", "BTC/USDT")
                from skills.report.flexible_report.service import generate_analysis_report
                result = generate_analysis_report(symbol)
            else:
                result = {"error": f"Unknown report type: {report_type}"}
            
            # å¦‚æœæŒ‡å®šäº†å­˜å‚¨ç›®æ ‡ï¼Œä¿å­˜æŠ¥å‘Š
            if payload.storage_target and result.get("content"):
                from storage.base import get_storage_manager
                manager = get_storage_manager()
                storage_result = manager.save_to(
                    payload.storage_target,
                    "report",
                    result.get("content", ""),
                    title=result.get("title", "Report")
                )
                result["storage_result"] = {
                    "success": storage_result.success,
                    "location": storage_result.location
                }
            
            return ExecutionResult(
                success=True,
                output=result,
                execution_time=time.time() - start_time
            )
            
        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            return ExecutionResult(
                success=False,
                error=str(e),
                execution_time=time.time() - start_time
            )


class StorageSaveHandler(TaskHandler):
    """å­˜å‚¨ä¿å­˜ä»»åŠ¡å¤„ç†å™¨"""
    
    def can_handle(self, payload: TaskPayload) -> bool:
        return payload.task_type == TaskType.STORAGE_SAVE
    
    def execute(self, payload: TaskPayload) -> ExecutionResult:
        start_time = time.time()
        try:
            from storage.base import get_storage_manager
            
            manager = get_storage_manager()
            target = payload.storage_target or "file"
            content_type = payload.action or "report"
            content = payload.params.get("content", "")
            
            result = manager.save_to(
                target,
                content_type,
                content,
                **payload.params
            )
            
            return ExecutionResult(
                success=result.success,
                output={
                    "location": result.location,
                    "message": result.message
                },
                error=result.error,
                execution_time=time.time() - start_time
            )
            
        except Exception as e:
            logger.error(f"Storage save failed: {e}")
            return ExecutionResult(
                success=False,
                error=str(e),
                execution_time=time.time() - start_time
            )


class TaskExecutor:
    """ä»»åŠ¡æ‰§è¡Œå™¨"""
    
    def __init__(self, publisher: Optional[EnhancedCloudTaskPublisher] = None):
        self.publisher = publisher or EnhancedCloudTaskPublisher()
        self.handlers: List[TaskHandler] = []
        self._running = False
        self._thread: Optional[threading.Thread] = None
        self._poll_interval = 1.0  # ç§’
        
        # æ³¨å†Œé»˜è®¤å¤„ç†å™¨
        self._register_default_handlers()
    
    def _register_default_handlers(self) -> None:
        """æ³¨å†Œé»˜è®¤ä»»åŠ¡å¤„ç†å™¨"""
        self.register_handler(MarketAnalysisHandler())
        self.register_handler(AICallHandler())
        self.register_handler(ReportGenerationHandler())
        self.register_handler(StorageSaveHandler())
    
    def register_handler(self, handler: TaskHandler) -> None:
        """æ³¨å†Œä»»åŠ¡å¤„ç†å™¨"""
        self.handlers.append(handler)
    
    def find_handler(self, payload: TaskPayload) -> Optional[TaskHandler]:
        """æŸ¥æ‰¾åˆé€‚çš„å¤„ç†å™¨"""
        for handler in self.handlers:
            if handler.can_handle(payload):
                return handler
        return None
    
    def execute_task(self, task: EnhancedCloudTask) -> ExecutionResult:
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
        try:
            # è§£æ payload
            payload = TaskPayload.from_dict(task.payload)
            
            # æŸ¥æ‰¾å¤„ç†å™¨
            handler = self.find_handler(payload)
            if not handler:
                return ExecutionResult(
                    success=False,
                    error=f"No handler found for task type: {payload.task_type}"
                )
            
            # æ‰§è¡Œä»»åŠ¡
            logger.info(f"Executing task {task.task_id}: {payload.task_type.value}/{payload.action}")
            result = handler.execute(payload)
            
            return result
            
        except Exception as e:
            logger.error(f"Task execution error: {e}")
            return ExecutionResult(
                success=False,
                error=str(e)
            )
    
    def process_pending_tasks(self, limit: int = 10) -> int:
        """å¤„ç†å¾…æ‰§è¡Œçš„ä»»åŠ¡"""
        processed = 0
        
        # è·å–å‡†å¤‡å¥½çš„ä»»åŠ¡
        ready_tasks = self.publisher.get_ready_tasks(limit=limit)
        
        for task in ready_tasks:
            try:
                # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
                self.publisher.update_status(task.task_id, TaskStatus.RUNNING.value)
                
                # æ‰§è¡Œä»»åŠ¡
                result = self.execute_task(task)
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                if result.success:
                    self.publisher.update_status(
                        task.task_id,
                        TaskStatus.COMPLETED.value,
                        result={
                            "output": result.output,
                            "execution_time": result.execution_time,
                            "metadata": result.metadata
                        }
                    )
                else:
                    # æ£€æŸ¥æ˜¯å¦å¯ä»¥é‡è¯•
                    if task.retry_count < task.max_retries:
                        self.publisher.retry_task(task.task_id)
                    else:
                        self.publisher.update_status(
                            task.task_id,
                            TaskStatus.FAILED.value,
                            error=result.error
                        )
                
                processed += 1
                
            except Exception as e:
                logger.error(f"Error processing task {task.task_id}: {e}")
                self.publisher.update_status(
                    task.task_id,
                    TaskStatus.FAILED.value,
                    error=str(e)
                )
        
        return processed
    
    def _worker_loop(self) -> None:
        """å·¥ä½œå¾ªç¯"""
        logger.info("Task executor worker started")
        
        while self._running:
            try:
                # æ¸…ç†è¿‡æœŸä»»åŠ¡
                self.publisher.cleanup_expired()
                
                # å¤„ç†å¾…æ‰§è¡Œä»»åŠ¡
                processed = self.process_pending_tasks()
                
                if processed > 0:
                    logger.info(f"Processed {processed} tasks")
                
            except Exception as e:
                logger.error(f"Worker loop error: {e}")
            
            time.sleep(self._poll_interval)
        
        logger.info("Task executor worker stopped")
    
    def start(self, poll_interval: float = 1.0) -> None:
        """å¯åŠ¨æ‰§è¡Œå™¨"""
        if self._running:
            return
        
        self._poll_interval = poll_interval
        self._running = True
        self._thread = threading.Thread(target=self._worker_loop, daemon=True)
        self._thread.start()
        
        logger.info("Task executor started")
    
    def stop(self) -> None:
        """åœæ­¢æ‰§è¡Œå™¨"""
        self._running = False
        if self._thread:
            self._thread.join(timeout=5.0)
            self._thread = None
        
        logger.info("Task executor stopped")
    
    def is_running(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿è¡Œä¸­"""
        return self._running


# å…¨å±€æ‰§è¡Œå™¨å®ä¾‹
_executor_instance: Optional[TaskExecutor] = None


def get_task_executor() -> TaskExecutor:
    """è·å–å…¨å±€ä»»åŠ¡æ‰§è¡Œå™¨"""
    global _executor_instance
    if _executor_instance is None:
        _executor_instance = TaskExecutor()
    return _executor_instance


def start_executor(poll_interval: float = 1.0) -> TaskExecutor:
    """å¯åŠ¨å…¨å±€ä»»åŠ¡æ‰§è¡Œå™¨"""
    executor = get_task_executor()
    executor.start(poll_interval)
    return executor


def stop_executor() -> None:
    """åœæ­¢å…¨å±€ä»»åŠ¡æ‰§è¡Œå™¨"""
    global _executor_instance
    if _executor_instance:
        _executor_instance.stop()


# ä¾¿æ·å‡½æ•°
def submit_task(
    task_type: Union[str, TaskType],
    action: str,
    params: Optional[Dict] = None,
    priority: int = TaskPriority.NORMAL.value,
    timeout: Optional[float] = None,
    depends_on: Optional[List[str]] = None,
    storage_target: Optional[str] = None,
    notify_on_complete: bool = False,
) -> str:
    """
    æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹
        action: å…·ä½“åŠ¨ä½œ
        params: ä»»åŠ¡å‚æ•°
        priority: ä¼˜å…ˆçº§
        timeout: è¶…æ—¶æ—¶é—´
        depends_on: ä¾èµ–ä»»åŠ¡ ID åˆ—è¡¨
        storage_target: å­˜å‚¨ç›®æ ‡
        notify_on_complete: å®Œæˆåæ˜¯å¦é€šçŸ¥
    
    Returns:
        str: ä»»åŠ¡ ID
    """
    from .enhanced_publisher import EnhancedCloudTaskPublisher
    
    publisher = EnhancedCloudTaskPublisher()
    
    if isinstance(task_type, str):
        try:
            task_type = TaskType(task_type)
        except ValueError:
            task_type = TaskType.CUSTOM
    
    payload = TaskPayload(
        task_type=task_type,
        action=action,
        params=params or {},
        storage_target=storage_target,
        notify_on_complete=notify_on_complete,
    )
    
    task = publisher.publish(
        name=f"{task_type.value}_{action}",
        payload=payload.to_dict(),
        priority=priority,
        timeout=timeout,
        depends_on=depends_on,
        tags=[task_type.value, action]
    )
    
    return task.task_id


# å¯¼å‡º
__all__ = [
    "TaskType",
    "TaskPayload",
    "ExecutionResult",
    "TaskHandler",
    "TaskExecutor",
    "get_task_executor",
    "start_executor",
    "stop_executor",
    "submit_task",
]
