"""
æ‰¹å¤„ç†è„šæœ¬ï¼šä¸ºä»“åº“å†…æ‰€æœ‰ Python ä»£ç æ–‡ä»¶æ·»åŠ æ ‡å‡†åŒ–æ–‡ä»¶å¤´æ³¨é‡Šï¼ˆä»»åŠ¡.txt-ä»»åŠ¡1ï¼‰ã€‚

æ‰§è¡Œç›®æ ‡ï¼š
1) æ‰«æé¡¹ç›®ä¸­æ‰€æœ‰ .py æ–‡ä»¶ï¼ˆæŽ’é™¤è™šæ‹ŸçŽ¯å¢ƒä¸Žç¼“å­˜ç›®å½•ï¼‰
2) ä¸ºæ¯ä¸ªæ–‡ä»¶æ™ºèƒ½ç”Ÿæˆç¬¦åˆå…¶å®žé™…åŠŸèƒ½çš„å¤´æ³¨é‡Šï¼ˆåŸºäºŽè·¯å¾„/æ–‡ä»¶å/docstring/å…³é”®å­—ï¼‰
3) è‡ªåŠ¨æå– import ä¾èµ–ä½œä¸ºâ€œæ–‡ä»¶ç»“æž„â€éƒ¨åˆ†ï¼ˆæŒ‰ æ ‡å‡†åº“/ç¬¬ä¸‰æ–¹/æœ¬åœ° åˆ†ç»„ï¼‰
4) ä¿ç•™åŽŸæœ‰çš„ shebang ä¸Ž encoding å£°æ˜Ž
5) ä¸ä¿®æ”¹åŽŸæœ‰ä¸šåŠ¡é€»è¾‘ä»£ç ï¼ˆåªæ’å…¥æ³¨é‡Šå—ï¼‰
"""

from __future__ import annotations

import argparse
import ast
import os
import re
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Iterable, List, Sequence, Set, Tuple

_BEIJING_TZ = timezone(timedelta(hours=8))

EXCLUDED_DIRS: Set[str] = {
    ".git",
    "__pycache__",
    "venv",
    ".venv",
    "site-packages",
    "node_modules",
    ".tox",
    "dist",
    "build",
    "egg-info",
    ".mypy_cache",
    ".ruff_cache",
}

HEADER_BORDER = "############################################################"
HEADER_MARKER = "# ðŸ“˜ æ–‡ä»¶è¯´æ˜Žï¼š"

_ENCODING_RE = re.compile(r"coding[:=]\s*([-\w.]+)")
_LOCAL_TOPLEVEL = {"core", "tools", "skills", "storage", "utils"}


def _beijing_date() -> str:
    return datetime.now(_BEIJING_TZ).strftime("%Y-%m-%d")


def _detect_newline_style(raw: bytes) -> str:
    return "\r\n" if b"\r\n" in raw else "\n"


def _read_text_utf8(path: Path) -> Tuple[str, str, bool]:
    raw = path.read_bytes()
    newline = _detect_newline_style(raw)
    had_trailing_newline = raw.endswith(b"\n")

    for enc in ("utf-8", "utf-8-sig"):
        try:
            return raw.decode(enc), newline, had_trailing_newline
        except UnicodeDecodeError:
            continue
    raise UnicodeDecodeError("utf-8", raw, 0, 1, "file is not valid utf-8")


def _write_text_utf8(path: Path, text: str, newline: str, trailing_newline: bool) -> None:
    if trailing_newline and not text.endswith("\n"):
        text += "\n"
    if not trailing_newline:
        text = text.rstrip("\n")
    with path.open("w", encoding="utf-8", newline=newline) as f:
        f.write(text)


def _header_exists(text: str) -> bool:
    head = "\n".join(text.splitlines()[:80])
    return HEADER_MARKER in head and HEADER_BORDER in head


def _split_preserve_preamble(lines: Sequence[str]) -> Tuple[List[str], List[str]]:
    preserved: List[str] = []
    idx = 0
    while idx < len(lines):
        line = lines[idx]
        stripped = line.strip()
        if idx == 0 and stripped.startswith("#!"):
            preserved.append(line)
            idx += 1
            continue
        if stripped.startswith("#") and _ENCODING_RE.search(stripped):
            preserved.append(line)
            idx += 1
            continue
        break
    return preserved, list(lines[idx:])


def _safe_first_line(text: str) -> str:
    for line in (text or "").splitlines():
        line = line.strip()
        if line:
            return line
    return ""


def _extract_docstring_and_imports(source: str) -> Tuple[str, List[str]]:
    try:
        tree = ast.parse(source)
    except SyntaxError:
        return "", _extract_imports_regex(source)

    doc = ast.get_docstring(tree) or ""
    imports: List[str] = []
    for node in tree.body:
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports.append(alias.name)
        elif isinstance(node, ast.ImportFrom):
            module = node.module or ""
            prefix = "." * (node.level or 0)
            imports.append(prefix + module if module else prefix)
    return doc, imports


def _extract_imports_regex(source: str) -> List[str]:
    out: List[str] = []
    for line in source.splitlines():
        stripped = line.strip()
        if stripped.startswith("import "):
            name = stripped[len("import ") :].split(" as ")[0].split(",")[0].strip()
            if name:
                out.append(name)
        if stripped.startswith("from ") and " import " in stripped:
            name = stripped[len("from ") :].split(" import ")[0].strip()
            if name:
                out.append(name)
    return out


def _categorize_imports(modules: Sequence[str]) -> Tuple[List[str], List[str], List[str]]:
    stdlib: Set[str] = set()
    third: Set[str] = set()
    local: Set[str] = set()

    stdlib_names = getattr(sys, "stdlib_module_names", set())

    for mod in modules:
        mod = (mod or "").strip()
        if not mod:
            continue
        if mod.startswith("."):
            local.add(mod)
            continue

        top = mod.split(".")[0]
        if top in _LOCAL_TOPLEVEL:
            local.add(mod)
        elif top in stdlib_names:
            stdlib.add(top)
        else:
            third.add(top)

    return sorted(stdlib), sorted(third), sorted(local)


def _format_dep_list(items: Sequence[str], *, max_items: int = 12) -> str:
    items = [x for x in items if x]
    if not items:
        return "æ— "
    if len(items) <= max_items:
        return ", ".join(items)
    head = ", ".join(list(items)[:max_items])
    return f"{head} ... ç­‰ {len(items)} ä¸ª"


def _guess_description(rel_path: str, docstring: str, source: str) -> str:
    first_doc = _safe_first_line(docstring)
    if 6 <= len(first_doc) <= 120:
        return first_doc

    name = Path(rel_path).stem
    if name == "__init__":
        return "åŒ…åˆå§‹åŒ–ï¼šèšåˆå¯¼å‡ºç¬¦å·å¹¶æä¾›ç¨³å®šçš„å¯¼å…¥å…¥å£ã€‚"

    lowered = (rel_path + "\n" + source[:4000]).lower()
    if rel_path.replace("\\", "/").startswith("tests/"):
        return f"æµ‹è¯•ç”¨ä¾‹ï¼šéªŒè¯ {name} ç›¸å…³é€»è¾‘çš„æ­£ç¡®æ€§ä¸Žå›žå½’ã€‚"
    if "mcp" in lowered and ("fastmcp" in lowered or "mcp.tool" in lowered):
        return "MCP ç›¸å…³æ¨¡å—ï¼šå®šä¹‰/å°è£…å·¥å…·è°ƒç”¨å¹¶å¼ºåŒ– stdout åè®®å®‰å…¨ã€‚"
    if "redis" in lowered:
        return "Redis ç›¸å…³æ¨¡å—ï¼šæä¾›é˜Ÿåˆ—/ç¼“å­˜/ä»»åŠ¡é€šä¿¡çš„é€‚é…ä¸Žå°è£…ã€‚"
    if "smtp" in lowered or "smtplib" in lowered or "email" in lowered:
        return "é€šçŸ¥ä¸Žé‚®ä»¶æ¨¡å—ï¼šå°è£…æ¶ˆæ¯å‘é€/é€šçŸ¥åˆ†å‘èƒ½åŠ›ã€‚"
    if "ccxt" in lowered or "exchange" in lowered:
        return "äº¤æ˜“æ‰€ç›¸å…³æ¨¡å—ï¼šå°è£…è¡Œæƒ…/ä¸‹å•/è´¦æˆ·ç­‰æŽ¥å£è®¿é—®èƒ½åŠ›ã€‚"
    if "risk" in lowered:
        return "é£ŽæŽ§ç›¸å…³æ¨¡å—ï¼šæä¾›é£Žé™©æŽ§åˆ¶ã€èµ„é‡‘ç®¡ç†ä¸Žé™åˆ¶è§„åˆ™ã€‚"
    if "market" in lowered or "analysis" in lowered:
        return "å¸‚åœºç ”ç©¶/åˆ†æžæ¨¡å—ï¼šæä¾›æ•°æ®åˆ†æžã€è´¨é‡è¯„ä¼°ä¸Žç ”ç©¶è¾…åŠ©èƒ½åŠ›ã€‚"
    if "logger" in lowered or "logging" in lowered:
        return "æ—¥å¿—æ¨¡å—ï¼šæä¾›ç»“æž„åŒ–æ—¥å¿—ã€åˆ†é€šé“è¾“å‡ºä¸Žæ€§èƒ½è®°å½•èƒ½åŠ›ã€‚"

    parts = rel_path.replace("\\", "/").split("/")
    if parts[:2] == ["src", "core"]:
        return f"æ ¸å¿ƒæ¨¡å—ï¼šæä¾› {name} ç›¸å…³çš„åŸºç¡€èƒ½åŠ›ä¸Žå…¬å…±æŽ¥å£ã€‚"
    if parts[:2] == ["src", "tools"]:
        return f"MCP å·¥å…·æ¨¡å—ï¼šæä¾› {name} ç›¸å…³å·¥å…·å¹¶å¯¹æŽ¥ skills/core/storageã€‚"
    if parts[:2] == ["src", "skills"]:
        return f"æŠ€èƒ½æ¨¡å—ï¼šå®žçŽ° {name} ç›¸å…³çš„ä¸šåŠ¡èƒ½åŠ›å°è£…ä¸Žç»„åˆè°ƒç”¨ã€‚"
    if parts[:2] == ["src", "storage"]:
        return f"å­˜å‚¨é€‚é…æ¨¡å—ï¼šå®žçŽ° {name} ç›¸å…³çš„å­˜å‚¨è¯»å†™ä¸Žå¤–éƒ¨æœåŠ¡å¯¹æŽ¥ã€‚"
    if parts[:2] == ["src", "utils"]:
        return f"é€šç”¨å·¥å…·æ¨¡å—ï¼šæä¾› {name} ç›¸å…³çš„è¾…åŠ©å‡½æ•°ä¸ŽåŸºç¡€ç»„ä»¶ã€‚"
    if parts and parts[0] in {"scripts", "dev"}:
        return f"å·¥ç¨‹è„šæœ¬ï¼šæä¾› {name} çš„è‡ªåŠ¨åŒ–å·¥å…·ä¸Žæ‰¹å¤„ç†èƒ½åŠ›ã€‚"

    return f"æ¨¡å—ï¼š{name}ï¼ˆæä¾›ç›¸å…³åŠŸèƒ½å®žçŽ°ä¸Žå…¬å…±æŽ¥å£ï¼‰ã€‚"


def _render_header(rel_path: str, description: str, imports: Sequence[str]) -> str:
    stdlib, third, local = _categorize_imports(imports)

    lines = [
        HEADER_BORDER,
        "# ðŸ“˜ æ–‡ä»¶è¯´æ˜Žï¼š",
        f"# æœ¬æ–‡ä»¶å®žçŽ°çš„åŠŸèƒ½ï¼š{description}",
        "#",
        "# ðŸ“‹ ç¨‹åºæ•´ä½“ä¼ªä»£ç ï¼ˆä¸­æ–‡ï¼‰ï¼š",
        "# 1. åˆå§‹åŒ–ä¸»è¦ä¾èµ–ä¸Žå˜é‡",
        "# 2. åŠ è½½è¾“å…¥æ•°æ®æˆ–æŽ¥æ”¶å¤–éƒ¨è¯·æ±‚",
        "# 3. æ‰§è¡Œä¸»è¦é€»è¾‘æ­¥éª¤ï¼ˆå¦‚è®¡ç®—ã€å¤„ç†ã€è®­ç»ƒã€æ¸²æŸ“ç­‰ï¼‰",
        "# 4. è¾“å‡ºæˆ–è¿”å›žç»“æžœ",
        "# 5. å¼‚å¸¸å¤„ç†ä¸Žèµ„æºé‡Šæ”¾",
        "#",
        "# ðŸ”„ ç¨‹åºæµç¨‹å›¾ï¼ˆé€»è¾‘æµï¼‰ï¼š",
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
        "# â”‚  è¾“å…¥æ•°æ® â”‚",
        "# â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜",
        "#       â†“",
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
        "# â”‚  æ ¸å¿ƒå¤„ç†é€»è¾‘ â”‚",
        "# â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜",
        "#       â†“",
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
        "# â”‚  è¾“å‡ºç»“æžœ â”‚",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
        "#",
        "# ðŸ“Š æ•°æ®ç®¡é“è¯´æ˜Žï¼š",
        "# æ•°æ®æµå‘ï¼šè¾“å…¥æº â†’ æ•°æ®æ¸…æ´—/è½¬æ¢ â†’ æ ¸å¿ƒç®—æ³•æ¨¡å— â†’ è¾“å‡ºç›®æ ‡ï¼ˆæ–‡ä»¶ / æŽ¥å£ / ç»ˆç«¯ï¼‰",
        "#",
        "# ðŸ§© æ–‡ä»¶ç»“æž„ï¼š",
        f"# - ä¾èµ–ï¼ˆæ ‡å‡†åº“ï¼‰ï¼š{_format_dep_list(stdlib)}",
        f"# - ä¾èµ–ï¼ˆç¬¬ä¸‰æ–¹ï¼‰ï¼š{_format_dep_list(third)}",
        f"# - ä¾èµ–ï¼ˆæœ¬åœ°ï¼‰ï¼š{_format_dep_list(local)}",
        "#",
        f"# ðŸ•’ åˆ›å»ºæ—¶é—´ï¼š{_beijing_date()}",
        HEADER_BORDER,
        "",
    ]
    return "\n".join(lines)


def process_file(path: Path, base: Path, dry_run: bool = False) -> bool:
    try:
        text, newline, trailing_newline = _read_text_utf8(path)
    except Exception as exc:
        print(f"[WARN] read failed {path}: {exc}")
        return False

    if _header_exists(text):
        return True

    rel_path = str(path.relative_to(base)).replace("\\", "/")
    docstring, imports = _extract_docstring_and_imports(text)
    description = _guess_description(rel_path, docstring, text)
    header = _render_header(rel_path, description, imports)

    lines = text.splitlines()
    preserved, remainder = _split_preserve_preamble(lines)
    new_content = "\n".join(preserved + [header] + remainder)

    if dry_run:
        print(f"[DRY] would update {rel_path}")
        return True

    try:
        _write_text_utf8(path, new_content, newline, trailing_newline)
        print(f"[OK] header added: {rel_path}")
        return True
    except Exception as exc:
        print(f"[WARN] write failed {path}: {exc}")
        return False


def iter_python_files(root: Path) -> Iterable[Path]:
    for dirpath, dirnames, filenames in os.walk(root):
        dirnames[:] = [d for d in dirnames if d not in EXCLUDED_DIRS and not d.startswith(".")]
        for fname in filenames:
            if fname.endswith(".py"):
                yield Path(dirpath) / fname


def main() -> int:
    parser = argparse.ArgumentParser(description="Batch add standardized headers to Python files.")
    parser.add_argument("--path", default=".", help="Root directory to scan, default current.")
    parser.add_argument("--dry-run", action="store_true", help="Preview changes without writing.")
    args = parser.parse_args()

    root = Path(args.path).resolve()
    py_files = sorted(iter_python_files(root))
    print(f"[INFO] scanning {root} ({len(py_files)} python files)")

    success = 0
    failed = 0
    for file_path in py_files:
        if process_file(file_path, root, args.dry_run):
            success += 1
        else:
            failed += 1

    print(f"[SUMMARY] success={success} failed={failed} total={len(py_files)}")
    return 0 if failed == 0 else 1


if __name__ == "__main__":
    raise SystemExit(main())
